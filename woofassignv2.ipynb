{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7706649,"sourceType":"datasetVersion","datasetId":4499441}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-26T20:28:37.657758Z","iopub.execute_input":"2024-02-26T20:28:37.658305Z","iopub.status.idle":"2024-02-26T20:28:38.668491Z","shell.execute_reply.started":"2024-02-26T20:28:37.658264Z","shell.execute_reply":"2024-02-26T20:28:38.667332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras import initializers\nimport shutil","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:28:38.670416Z","iopub.execute_input":"2024-02-26T20:28:38.670990Z","iopub.status.idle":"2024-02-26T20:28:51.373756Z","shell.execute_reply.started":"2024-02-26T20:28:38.670958Z","shell.execute_reply":"2024-02-26T20:28:51.372732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !tar -xvf /kaggle/input/woof-assignmentpt2/imagewoof-320.tgz","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:46:03.685611Z","iopub.execute_input":"2024-02-26T19:46:03.686058Z","iopub.status.idle":"2024-02-26T19:46:03.692252Z","shell.execute_reply.started":"2024-02-26T19:46:03.686013Z","shell.execute_reply":"2024-02-26T19:46:03.691186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef merge_datasets(train_dir, val_dir, master_dir):\n    # Ensure the master directory exists\n    if not os.path.exists(master_dir):\n        os.makedirs(master_dir)\n\n    # Process each dataset directory (train, val)\n    for dataset_dir in [train_dir, val_dir]:\n        # List all class directories in the current dataset directory\n        for class_name in os.listdir(dataset_dir):\n            class_dir_path = os.path.join(dataset_dir, class_name)\n            # Skip if not a directory\n            if not os.path.isdir(class_dir_path):\n                continue\n\n            # Ensure corresponding class directory exists in the master directory\n            master_class_dir = os.path.join(master_dir, class_name)\n            if not os.path.exists(master_class_dir):\n                os.makedirs(master_class_dir)\n\n            # Copy all images from this class to the master directory\n            for image_name in os.listdir(class_dir_path):\n                source_image_path = os.path.join(class_dir_path, image_name)\n                destination_image_path = os.path.join(master_class_dir, image_name)\n\n                # To avoid overwriting, check if the file already exists\n                if not os.path.exists(destination_image_path):\n                    shutil.copy2(source_image_path, destination_image_path)\n                else:\n                    print(f\"Skipping {destination_image_path}, already exists.\")\n\n# Define your directory paths\ntrain_dir = '/kaggle/working/imagewoof-320/train'\nval_dir = '/kaggle/working/imagewoof-320/val'\nmaster_dir = '/kaggle/working/imagewoof-320/test'\n\n# Merge the datasets\nmerge_datasets(train_dir, val_dir, master_dir)\n\nprint(\"Merging completed.\")","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:46:07.687886Z","iopub.execute_input":"2024-02-26T19:46:07.688252Z","iopub.status.idle":"2024-02-26T19:46:09.906405Z","shell.execute_reply.started":"2024-02-26T19:46:07.688225Z","shell.execute_reply":"2024-02-26T19:46:09.905023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_files_in_subfolders(master_dir):\n    # Dictionary to hold the count of files in each subfolder\n    file_counts = {}\n\n    # List all items in the master directory\n    for subfolder in os.listdir(master_dir):\n        subfolder_path = os.path.join(master_dir, subfolder)\n        # Ensure the item is a directory\n        if os.path.isdir(subfolder_path):\n            # Count the number of files in this subfolder\n            file_counts[subfolder] = len([name for name in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, name))])\n\n    return file_counts\n\n# # Define your master directory path\n# master_dir = '/kaggle/working/imagenette2-160/test'\n\n# Get the file counts\nfile_counts = count_files_in_subfolders(master_dir)\n\n# Print the counts\nfor subfolder, count in file_counts.items():\n    print(f\"{subfolder}: {count} files\")","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:40:03.928200Z","iopub.execute_input":"2024-02-26T19:40:03.928906Z","iopub.status.idle":"2024-02-26T19:40:04.067258Z","shell.execute_reply.started":"2024-02-26T19:40:03.928860Z","shell.execute_reply":"2024-02-26T19:40:04.065902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_to_include = ['n02087394', 'n02096294','n02099601','n02111889']\nclasses_to_include\n#Correcting any accidental leading/trailing whitespace in class names\nclasses_to_include = [cls.strip() for cls in classes_to_include]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:48:48.576088Z","iopub.execute_input":"2024-02-26T19:48:48.576541Z","iopub.status.idle":"2024-02-26T19:48:48.582078Z","shell.execute_reply.started":"2024-02-26T19:48:48.576509Z","shell.execute_reply":"2024-02-26T19:48:48.581240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_subdirectories(directory):\n    subdirectories = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n    return subdirectories\n\nget_subdirectories(\"/kaggle/working/imagewoof-320/test\")","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:49:06.644658Z","iopub.execute_input":"2024-02-26T19:49:06.645035Z","iopub.status.idle":"2024-02-26T19:49:06.656604Z","shell.execute_reply.started":"2024-02-26T19:49:06.645009Z","shell.execute_reply":"2024-02-26T19:49:06.654962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef include_subdirectories(directory, classes_to_include):\n    sub_dir_list = get_subdirectories(directory)\n    for c in sub_dir_list:\n        # If the subdirectory is not in the list of classes to include\n        if c not in classes_to_include:\n            # Construct the path to the subdirectory\n            dir_to_delete = os.path.join(directory, c)\n            # Remove the subdirectory and all its contents\n            shutil.rmtree(dir_to_delete)\n            print(f\"Deleted: {dir_to_delete}\")\ninclude_subdirectories('/kaggle/working/imagewoof-320/test', classes_to_include)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:49:35.399314Z","iopub.execute_input":"2024-02-26T19:49:35.399806Z","iopub.status.idle":"2024-02-26T19:49:35.691876Z","shell.execute_reply.started":"2024-02-26T19:49:35.399775Z","shell.execute_reply":"2024-02-26T19:49:35.690606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install split-folders[full]","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:52:11.159866Z","iopub.execute_input":"2024-02-26T19:52:11.160317Z","iopub.status.idle":"2024-02-26T19:52:28.087588Z","shell.execute_reply.started":"2024-02-26T19:52:11.160285Z","shell.execute_reply":"2024-02-26T19:52:28.086624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import splitfolders\n# Split with a ratio.\n# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\nsplitfolders.ratio(\"/kaggle/working/imagewoof-320/test\", output=\"TrainTestValidation\",\n    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False) # default values\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T19:52:37.594026Z","iopub.execute_input":"2024-02-26T19:52:37.594481Z","iopub.status.idle":"2024-02-26T19:52:38.698269Z","shell.execute_reply.started":"2024-02-26T19:52:37.594439Z","shell.execute_reply":"2024-02-26T19:52:38.696784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dataset = image_dataset_from_directory(\n\"/kaggle/working/TrainTestValidation/train\",\nimage_size=(299,299),\nbatch_size=32)\n\nval_dataset = image_dataset_from_directory(\n\"/kaggle/working/TrainTestValidation/val\",\nimage_size=(299,299),\nbatch_size=32)\n\ntest_dataset = image_dataset_from_directory(\n\"/kaggle/working/TrainTestValidation/test\",\nimage_size=(299,299),\nbatch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:28:59.364628Z","iopub.execute_input":"2024-02-26T20:28:59.365427Z","iopub.status.idle":"2024-02-26T20:28:59.779649Z","shell.execute_reply.started":"2024-02-26T20:28:59.365397Z","shell.execute_reply":"2024-02-26T20:28:59.778913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_dataset.take(1):\n    print(images.shape)  # Should be (batch_size, 299, 299, 3)\n    print(labels.shape)  # Should be (batch_size,) for sparse_categorical_crossentropy\n    print(labels.dtype)  # Should be tf.int32 or tf.int64","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:31:45.361478Z","iopub.execute_input":"2024-02-26T20:31:45.361860Z","iopub.status.idle":"2024-02-26T20:31:45.696140Z","shell.execute_reply.started":"2024-02-26T20:31:45.361832Z","shell.execute_reply":"2024-02-26T20:31:45.695165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Want to get example of each class to see what they look like\n#Want to be able to resuse code after augmentation\n#Write funcitons to do this\ntrain_datasetViz = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/imagewoof-320/train\",\n    image_size=(299, 299),\n    batch_size=32,\n    shuffle=True,\n    seed=42\n)\n\ndef filter_class(images, labels, class_index):\n    return tf.equal(labels, class_index)\n\ndef apply_filter(dataset, class_index):\n    filtered_dataset = dataset.unbatch().filter(lambda image, label: filter_class(image, label, class_index)).batch(3)\n    return filtered_dataset\n\ndef make_plot_data_set_viz(filtered_dataset, class_index):\n    plt.figure(figsize=(10, 10))\n    for images, labels in filtered_dataset.take(1):\n        for i in range(3):  # Looping through 3 examples\n            ax = plt.subplot(1, 3, i + 1)  # Adjust subplot for a row of 3 images\n            plt.imshow(images[i].numpy().astype(\"uint8\"))\n            plt.title(f'Class {class_index}')\n            plt.axis(\"off\")\n    plt.show()\n\ndef filter_and_plot_class_tfdataset(dataset, class_index):\n    # Apply the filter\n    filtered_dataset = apply_filter(dataset, class_index)\n    # Make plot\n    make_plot_data_set_viz(filtered_dataset, class_index)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:20:08.697811Z","iopub.execute_input":"2024-02-26T20:20:08.698252Z","iopub.status.idle":"2024-02-26T20:20:09.614781Z","shell.execute_reply.started":"2024-02-26T20:20:08.698212Z","shell.execute_reply":"2024-02-26T20:20:09.613408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in range(6):\n    filter_and_plot_class_tfdataset(train_dataset,x)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:20:12.722701Z","iopub.execute_input":"2024-02-26T20:20:12.723133Z","iopub.status.idle":"2024-02-26T20:20:17.578756Z","shell.execute_reply.started":"2024-02-26T20:20:12.723101Z","shell.execute_reply":"2024-02-26T20:20:17.577576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\n\nconv_base = InceptionV3(\n    weights='imagenet',\n    include_top=False)\n\nfor layer in conv_base.layers[:-62]: # Chollet 8.27\n    layer.trainable = False\n\ninputs = keras.Input(shape=(299,299,3))\nx = layers.Rescaling(1./255)(inputs)\nx = conv_base(x)\nx= layers.Flatten()(x)\noutputs = layers.Dense(4, activation = 'softmax')(x)\n\nmodel1 = keras.Model(inputs=inputs, outputs=outputs)\n\nmodel1.compile(loss = 'sparse_categorical_crossentropy',\n                 optimizer = \"adam\",\n                 metrics =[\"accuracy\"])\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\n    filepath =\"InceptionV3_Finetune1.keras\",\n    save_best_only=True,\n    monitor=\"val_loss\"),\n     keras.callbacks.EarlyStopping(\n        monitor='val_loss', \n        patience=3,  # Number of epochs with no improvement after which training will be stopped\n        restore_best_weights=True\n    )\n]\n\nhistory = model1.fit(\ntrain_dataset,\nepochs=100,\nvalidation_data=val_dataset,\ncallbacks = callbacks)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:36:23.615399Z","iopub.execute_input":"2024-02-26T20:36:23.616048Z","iopub.status.idle":"2024-02-26T20:38:44.068721Z","shell.execute_reply.started":"2024-02-26T20:36:23.616016Z","shell.execute_reply":"2024-02-26T20:38:44.067580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1.save('my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:39:01.116103Z","iopub.execute_input":"2024-02-26T20:39:01.116813Z","iopub.status.idle":"2024-02-26T20:39:01.784769Z","shell.execute_reply.started":"2024-02-26T20:39:01.116784Z","shell.execute_reply":"2024-02-26T20:39:01.783959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nval_images, val_labels = next(iter(val_dataset.unbatch().batch(len(val_dataset))))\npredictions = model1.predict(val_images)\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = val_labels.numpy()\n\n# Compute confusion matrix\ncm = confusion_matrix(true_classes, predicted_classes)\n\n# Display confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()\n\n# Calculate per-class accuracy\nper_class_accuracy = cm.diagonal() / cm.sum(axis=1)\nfor idx, acc in enumerate(per_class_accuracy):\n    print(f\"Class {idx} accuracy: {acc*100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:41:27.135180Z","iopub.execute_input":"2024-02-26T20:41:27.136110Z","iopub.status.idle":"2024-02-26T20:41:31.335642Z","shell.execute_reply.started":"2024-02-26T20:41:27.136065Z","shell.execute_reply":"2024-02-26T20:41:31.334748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\naccuracy = history.history[\"accuracy\"]\nval_accuracy = history.history[\"val_accuracy\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\nepochs = range(1, len(accuracy) + 1)\nplt.plot(epochs ,accuracy, \"bo\", label = \"Training Accuracy\")\nplt.plot(epochs ,val_accuracy, \"b\", label = \"Validation Accuracy\")             \nplt.title(\"Training and validation accuracy\")\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, \"bo\", label= \"Training loss\")\nplt.plot(epochs, val_loss, \"b\", label=\" Validation loss\")\nplt.title(\"Training and Validation Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:41:41.374162Z","iopub.execute_input":"2024-02-26T20:41:41.375209Z","iopub.status.idle":"2024-02-26T20:41:41.828379Z","shell.execute_reply.started":"2024-02-26T20:41:41.375179Z","shell.execute_reply":"2024-02-26T20:41:41.827334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}